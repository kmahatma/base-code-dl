{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"},"colab":{"name":"ui-w3-a-intropytorch.ipynb","provenance":[{"file_id":"https://github.com/pytorch/tutorials/blob/gh-pages/_downloads/b13fe25e4dd1e4b0fd5f5ce803bde74b/tensorqs_tutorial.ipynb","timestamp":1633847685545}]}},"cells":[{"cell_type":"code","metadata":{"id":"MAfIV3wA3icR"},"source":["%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"it1e2cmC3icU"},"source":["\n","`Learn the Basics <intro.html>`_ ||\n","`Quickstart <quickstart_tutorial.html>`_ ||\n","**Tensors** ||\n","`Datasets & DataLoaders <data_tutorial.html>`_ ||\n","`Transforms <transforms_tutorial.html>`_ ||\n","`Build Model <buildmodel_tutorial.html>`_ ||\n","`Autograd <autogradqs_tutorial.html>`_ ||\n","`Optimization <optimization_tutorial.html>`_ ||\n","`Save & Load Model <saveloadrun_tutorial.html>`_\n","\n","Tensors\n","==========================\n","\n","Tensors are a specialized data structure that are very similar to arrays and matrices.\n","In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters.\n","\n","Tensors are similar to `NumPy’s <https://numpy.org/>`_ ndarrays, except that tensors can run on GPUs or other hardware accelerators. In fact, tensors and\n","NumPy arrays can often share the same underlying memory, eliminating the need to copy data (see `bridge-to-np-label`). Tensors\n","are also optimized for automatic differentiation (we'll see more about that later in the `Autograd <autogradqs_tutorial.html>`__\n","section). If you’re familiar with ndarrays, you’ll be right at home with the Tensor API. If not, follow along!\n","\n"]},{"cell_type":"code","metadata":{"id":"EtqDMK133icV","executionInfo":{"status":"ok","timestamp":1634106455808,"user_tz":-420,"elapsed":27010,"user":{"displayName":"kodrat m","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17273160718280629535"}}},"source":["import torch\n","import numpy as np"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AjQx_ph_3icW"},"source":["Initializing a Tensor\n","~~~~~~~~~~~~~~~~~~~~~\n","\n","Tensors can be initialized in various ways. Take a look at the following examples:\n","\n","**Directly from data**\n","\n","Tensors can be created directly from data. The data type is automatically inferred.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dBY_L2P_3icW","executionInfo":{"status":"ok","timestamp":1634107958002,"user_tz":-420,"elapsed":424,"user":{"displayName":"kodrat m","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17273160718280629535"}},"outputId":"540978fb-5489-4180-ddb0-c0d58e2e4105"},"source":["data = [[1, 2],[3, 4]]\n","x_data = torch.tensor(data)\n","x_data"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 2],\n","        [3, 4]])"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"BFKo8xFN3icX"},"source":["**From a NumPy array**\n","\n","Tensors can be created from NumPy arrays (and vice versa - see `bridge-to-np-label`).\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VKKyBYhN3icX","executionInfo":{"status":"ok","timestamp":1634107960263,"user_tz":-420,"elapsed":346,"user":{"displayName":"kodrat m","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17273160718280629535"}},"outputId":"487b9a29-efb4-4223-e6db-b42f26519ba8"},"source":["np_array = np.array(data)\n","x_np = torch.from_numpy(np_array)\n","x_np"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 2],\n","        [3, 4]])"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"7MNBFA1t5P4W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633847596157,"user_tz":-420,"elapsed":28283,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"97fa8ada-3a11-4c2c-fe3c-a603dee604e7"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","# drive.mount('/content/gdrive/My Drive/Colab Notebooks/')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"markdown","metadata":{"id":"zWF5kaeE3icY"},"source":["**From another tensor:**\n","\n","The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden.\n","\n"]},{"cell_type":"code","metadata":{"id":"uZllJ82v3icY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634107963731,"user_tz":-420,"elapsed":335,"user":{"displayName":"kodrat m","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17273160718280629535"}},"outputId":"0a1b9665-12dd-4ea8-d7b1-0dcc62724f04"},"source":["x_ones = torch.ones_like(x_data) # retains the properties of x_data\n","print(f\"Ones Tensor: \\n {x_ones} \\n\")\n","\n"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Ones Tensor: \n"," tensor([[1, 1],\n","        [1, 1]]) \n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E07RO3vq6hZs","executionInfo":{"status":"ok","timestamp":1634107966899,"user_tz":-420,"elapsed":336,"user":{"displayName":"kodrat m","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17273160718280629535"}},"outputId":"5ba4e41c-08f7-4995-a552-5ee24ae9686e"},"source":["x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n","print(f\"Random Tensor: \\n {x_rand} \\n\")"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Random Tensor: \n"," tensor([[0.6642, 0.0822],\n","        [0.1201, 0.5501]]) \n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"ElLHbNFr3icZ"},"source":["**With random or constant values:**\n","\n","``shape`` is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of the output tensor.\n","\n"]},{"cell_type":"code","metadata":{"id":"ucABOd4C3icZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634107970373,"user_tz":-420,"elapsed":315,"user":{"displayName":"kodrat m","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17273160718280629535"}},"outputId":"7e82c823-bb84-42be-fb0e-4ba288ba5471"},"source":["shape = (2,3,)\n","rand_tensor = torch.rand(shape)\n","ones_tensor = torch.ones(shape)\n","zeros_tensor = torch.zeros(shape)\n","\n","print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n","print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n","print(f\"Zeros Tensor: \\n {zeros_tensor}\")"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Random Tensor: \n"," tensor([[0.8422, 0.5459, 0.6472],\n","        [0.7808, 0.7043, 0.6897]]) \n","\n","Ones Tensor: \n"," tensor([[1., 1., 1.],\n","        [1., 1., 1.]]) \n","\n","Zeros Tensor: \n"," tensor([[0., 0., 0.],\n","        [0., 0., 0.]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"V4O4k7kK3ica"},"source":["--------------\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"kCcKxkcZ3ica"},"source":["Attributes of a Tensor\n","~~~~~~~~~~~~~~~~~\n","\n","Tensor attributes describe their shape, datatype, and the device on which they are stored.\n","\n"]},{"cell_type":"code","metadata":{"id":"MMyu7d7m3icb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634107974786,"user_tz":-420,"elapsed":314,"user":{"displayName":"kodrat m","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17273160718280629535"}},"outputId":"deaafd7b-7366-4b1e-cae5-04df24814c21"},"source":["tensor = torch.rand(3,4)\n","\n","print(f\"Shape of tensor: {tensor.shape}\")\n","print(f\"Datatype of tensor: {tensor.dtype}\")\n","print(f\"Device tensor is stored on: {tensor.device}\")"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of tensor: torch.Size([3, 4])\n","Datatype of tensor: torch.float32\n","Device tensor is stored on: cpu\n"]}]},{"cell_type":"markdown","metadata":{"id":"q4FkWBIf3icb"},"source":["--------------\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GLttUl6_3icb"},"source":["Operations on Tensors\n","~~~~~~~~~~~~~~~~~\n","\n","Over 100 tensor operations, including arithmetic, linear algebra, matrix manipulation (transposing,\n","indexing, slicing), sampling and more are\n","comprehensively described `here <https://pytorch.org/docs/stable/torch.html>`__.\n","\n","Each of these operations can be run on the GPU (at typically higher speeds than on a\n","CPU). If you’re using Colab, allocate a GPU by going to Runtime > Change runtime type > GPU.\n","\n","By default, tensors are created on the CPU. We need to explicitly move tensors to the GPU using\n","``.to`` method (after checking for GPU availability). Keep in mind that copying large tensors\n","across devices can be expensive in terms of time and memory!\n","\n"]},{"cell_type":"code","metadata":{"id":"V3xT0Y7f3icc","executionInfo":{"status":"ok","timestamp":1634107981240,"user_tz":-420,"elapsed":4,"user":{"displayName":"kodrat m","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17273160718280629535"}}},"source":["# We move our tensor to the GPU if available\n","if torch.cuda.is_available():\n","    tensor = tensor.to('cuda')"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X0jt50rQ3icc"},"source":["Try out some of the operations from the list.\n","If you're familiar with the NumPy API, you'll find the Tensor API a breeze to use.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"NLYdidWv3icc"},"source":["**Standard numpy-like indexing and slicing:**\n","\n"]},{"cell_type":"code","metadata":{"id":"7sqbPpqh3icc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634107985689,"user_tz":-420,"elapsed":311,"user":{"displayName":"kodrat m","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17273160718280629535"}},"outputId":"aa35ba87-109b-4f5f-d0c4-3ef7c8957c08"},"source":["tensor = torch.ones(4, 4)\n","print('First row: ', tensor[0])\n","print('First column: ', tensor[:, 0])\n","print('Last column:', tensor[..., -1])\n","tensor[:,1] = 0\n","tensor[2,:] = 0\n","print(tensor)"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["First row:  tensor([1., 1., 1., 1.])\n","First column:  tensor([1., 1., 1., 1.])\n","Last column: tensor([1., 1., 1., 1.])\n","tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [0., 0., 0., 0.],\n","        [1., 0., 1., 1.]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"DSnUhI7M3icd"},"source":["**Joining tensors** You can use ``torch.cat`` to concatenate a sequence of tensors along a given dimension.\n","See also `torch.stack <https://pytorch.org/docs/stable/generated/torch.stack.html>`__,\n","another tensor joining op that is subtly different from ``torch.cat``.\n","\n"]},{"cell_type":"code","metadata":{"id":"M0iOFpsy3ice","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634107994735,"user_tz":-420,"elapsed":334,"user":{"displayName":"kodrat m","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17273160718280629535"}},"outputId":"9796bf00-516d-4e57-e470-a9109d4fd418"},"source":["t1 = torch.cat([tensor, tensor, tensor], dim=1)\n","print(t1)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"Y388nsWi3ice"},"source":["**Arithmetic operations**\n","\n"]},{"cell_type":"code","metadata":{"id":"pi18gmqO3ice","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634108000048,"user_tz":-420,"elapsed":301,"user":{"displayName":"kodrat m","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17273160718280629535"}},"outputId":"39e07d30-39ad-43f3-926f-3d16bc22ef72"},"source":["# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n","y1 = tensor @ tensor.T\n","y2 = tensor.matmul(tensor.T)\n","\n","y3 = torch.rand_like(tensor)\n","torch.matmul(tensor, tensor.T, out=y3)\n","\n","y1\n"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[3., 3., 0., 3.],\n","        [3., 3., 0., 3.],\n","        [0., 0., 0., 0.],\n","        [3., 3., 0., 3.]])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UuVfa4uh8r4a","executionInfo":{"status":"ok","timestamp":1634108349911,"user_tz":-420,"elapsed":308,"user":{"displayName":"kodrat m","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17273160718280629535"}},"outputId":"8765446f-9cef-493b-eb68-f7a3e01c03f5"},"source":["\n","# This computes the element-wise product. z1, z2, z3 will have the same value\n","z1 = tensor * tensor\n","z2 = tensor.mul(tensor)\n","\n","z3 = torch.rand_like(tensor)\n","torch.mul(tensor, tensor, out=z3)\n","z1, z2"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[1., 0., 1., 1.],\n","         [1., 0., 1., 1.],\n","         [0., 0., 0., 0.],\n","         [1., 0., 1., 1.]]), tensor([[1., 0., 1., 1.],\n","         [1., 0., 1., 1.],\n","         [0., 0., 0., 0.],\n","         [1., 0., 1., 1.]]))"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"BfBSwr-j3ice"},"source":["**Single-element tensors** If you have a one-element tensor, for example by aggregating all\n","values of a tensor into one value, you can convert it to a Python\n","numerical value using ``item()``:\n","\n"]},{"cell_type":"code","metadata":{"id":"vpgKs8Ja3icf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634108377200,"user_tz":-420,"elapsed":6,"user":{"displayName":"kodrat m","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17273160718280629535"}},"outputId":"ad50b01a-6f6c-4fe1-9345-5b703d2b810a"},"source":["agg = tensor.sum()\n","agg_item = agg.item()\n","print(agg_item, type(agg_item))"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["9.0 <class 'float'>\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZuMmXugi3icf"},"source":["**In-place operations**\n","Operations that store the result into the operand are called in-place. They are denoted by a ``_`` suffix.\n","For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.\n","\n"]},{"cell_type":"code","metadata":{"id":"uz2QWDcW3icf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634108388140,"user_tz":-420,"elapsed":311,"user":{"displayName":"kodrat m","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17273160718280629535"}},"outputId":"18ab351a-d62a-41b0-eb52-07af45b0c82b"},"source":["print(tensor, \"\\n\")\n","tensor.add_(5)\n","print(tensor)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [0., 0., 0., 0.],\n","        [1., 0., 1., 1.]]) \n","\n","tensor([[6., 5., 6., 6.],\n","        [6., 5., 6., 6.],\n","        [5., 5., 5., 5.],\n","        [6., 5., 6., 6.]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"Hi8wA_Vx3icf"},"source":["<div class=\"alert alert-info\"><h4>Note</h4><p>In-place operations save some memory, but can be problematic when computing derivatives because of an immediate loss\n","     of history. Hence, their use is discouraged.</p></div>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"kbzcrdtA3icf"},"source":["--------------\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"0lD58HLH3icf"},"source":["\n","Bridge with NumPy\n","~~~~~~~~~~~~~~~~~\n","Tensors on the CPU and NumPy arrays can share their underlying memory\n","locations, and changing one will change\tthe other.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2wCpGT9H3icf"},"source":["Tensor to NumPy array\n","^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","\n"]},{"cell_type":"code","metadata":{"id":"S3hs8xzg3icf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634108395466,"user_tz":-420,"elapsed":332,"user":{"displayName":"kodrat m","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17273160718280629535"}},"outputId":"4bc1b069-8ea4-4aca-ff58-e1bc206bb3ba"},"source":["t = torch.ones(5)\n","print(f\"t: {t}\")\n","n = t.numpy()\n","print(f\"n: {n}\")"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["t: tensor([1., 1., 1., 1., 1.])\n","n: [1. 1. 1. 1. 1.]\n"]}]},{"cell_type":"markdown","metadata":{"id":"wYY-rOhT3icg"},"source":["A change in the tensor reflects in the NumPy array.\n","\n"]},{"cell_type":"code","metadata":{"id":"tiOkuJ_v3icg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634108399442,"user_tz":-420,"elapsed":296,"user":{"displayName":"kodrat m","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17273160718280629535"}},"outputId":"3147b10d-c75e-4c82-fd47-464c207bf323"},"source":["t.add_(1)\n","print(f\"t: {t}\")\n","print(f\"n: {n}\")"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["t: tensor([2., 2., 2., 2., 2.])\n","n: [2. 2. 2. 2. 2.]\n"]}]},{"cell_type":"markdown","metadata":{"id":"1qkYi1Fm3icg"},"source":["NumPy array to Tensor\n","^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","\n"]},{"cell_type":"code","metadata":{"id":"LlyA5PB43icg","executionInfo":{"status":"ok","timestamp":1634108437469,"user_tz":-420,"elapsed":310,"user":{"displayName":"kodrat m","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17273160718280629535"}}},"source":["n = np.ones(5)\n","t = torch.from_numpy(n)"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p2XjbMF33icg"},"source":["Changes in the NumPy array reflects in the tensor.\n","\n"]},{"cell_type":"code","metadata":{"id":"UnV-tZUX3icg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634108443528,"user_tz":-420,"elapsed":315,"user":{"displayName":"kodrat m","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17273160718280629535"}},"outputId":"9f8df169-04f5-47de-cc97-7a92b5424256"},"source":["np.add(n, 1, out=n)\n","print(f\"t: {t}\")\n","print(f\"n: {n}\")"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n","n: [2. 2. 2. 2. 2.]\n"]}]}]}